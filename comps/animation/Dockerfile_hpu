# Use a base image
# FROM python:3.11-slim
FROM vault.habana.ai/gaudi-docker/1.16.2/ubuntu22.04/habanalabs/pytorch-installer-2.2.2:latest AS hpu

# Set environment variables
ENV LANG=en_US.UTF-8
ENV PYTHONPATH=/home:/home/user:/usr/lib/habanalabs/:/optimum-habana
ENV PYTHON=/usr/bin/python3.10

# Install dependencies
RUN apt-get update -y && apt-get install -y --no-install-recommends --fix-missing \
    yasm \
    libx264-dev

# TO-DO: Add a user for security

# Install GenAIComps
RUN mkdir -p /home/user/comps
COPY comps /home/user/comps

# Install ppmpeg with x264 software codec
RUN git clone https://github.com/FFmpeg/FFmpeg.git /home/user/comps/animation/FFmpeg
WORKDIR /home/user/comps/animation/FFmpeg
RUN ./configure --enable-gpl --enable-libx264 && \
    make -j$(nproc-1) && \
    make install && \
    hash -r
RUN chmod +x $(which ffmpeg)

# Install Wav2Lip-GFPGAN
RUN git clone https://github.com/ajay-sainy/Wav2Lip-GFPGAN.git /home/user/comps/animation/Wav2Lip-GFPGAN

# Install gdown
RUN pip install gdown

# Download pre-trained models
WORKDIR /home/user/comps/animation/Wav2Lip-GFPGAN
RUN wget https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth -O Wav2Lip-master/face_detection/detection/sfd/s3fd.pth
RUN mkdir -p Wav2Lip-master/checkpoints
RUN gdown https://drive.google.com/uc?id=1mIKfu_onFKbkbrq6cKVRBblXe5bNMhd9 -O Wav2Lip-master/checkpoints/wav2lip.pth
RUN gdown https://drive.google.com/uc?id=1DD7dtUfNWqNoW-2Gnp78B4PyaiJ5ybhP -O Wav2Lip-master/checkpoints/wav2lip_gan.pth
RUN wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P GFPGAN-master/experiments/pretrained_models

# Install pip dependencies
RUN python3 -m pip install --upgrade pip
RUN pip install -r /home/user/comps/animation/requirements.txt

# Set the working directory
WORKDIR /home/user/comps/animation

# Define the command to run when the container starts
ENTRYPOINT [ "bash" ]
# ENTRYPOINT ["python", "animation.py", "--device", "hpu"]
